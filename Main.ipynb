{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library and Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T05:25:32.084983Z",
     "iopub.status.busy": "2024-11-10T05:25:32.084121Z",
     "iopub.status.idle": "2024-11-10T05:25:35.762792Z",
     "shell.execute_reply": "2024-11-10T05:25:35.762003Z",
     "shell.execute_reply.started": "2024-11-10T05:25:32.084935Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Modifikasi\n",
    "import warnings\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "#Perhitungan\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Imputasi\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV, GroupKFold,KFold, TimeSeriesSplit   \n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc,roc_auc_score, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, RepeatVector, TimeDistributed\n",
    "\n",
    "#Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# Feature Importance\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-10T05:25:36.156095Z",
     "iopub.status.busy": "2024-11-10T05:25:36.155218Z",
     "iopub.status.idle": "2024-11-10T05:25:36.531229Z",
     "shell.execute_reply": "2024-11-10T05:25:36.530217Z",
     "shell.execute_reply.started": "2024-11-10T05:25:36.156054Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('raw_dataset/Train.csv')\n",
    "test = pd.read_csv('raw_dataset/Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booma\\AppData\\Local\\Temp\\ipykernel_24164\\2488958140.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  train['Date'] = pd.to_datetime(train['Date'], dayfirst=True, errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "train['Date'] = pd.to_datetime(train['Date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "Date = train.copy()\n",
    "Date['Date'] = pd.to_datetime(Date['Date'])\n",
    "\n",
    "\n",
    "# 3. Menetapkan kolom Date sebagai index\n",
    "train.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booma\\AppData\\Local\\Temp\\ipykernel_24164\\1334361193.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  test['Date'] = pd.to_datetime(test['Date'], dayfirst=True, errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "test['Date'] = pd.to_datetime(test['Date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "Date_test = test.copy()\n",
    "Date_test['Date'] = pd.to_datetime(Date['Date'])\n",
    "\n",
    "\n",
    "# 3. Menetapkan kolom Date sebagai index\n",
    "test.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = train.copy()\n",
    "# df.drop(columns=['ID_Zindi','ID'],inplace=True)\n",
    "# test.drop(columns=['ID_Zindi','ID'],inplace=True)\n",
    "\n",
    "# def impute_missing_values(df, cols_to_impute, drop_cols=['LAT', 'LON'], n_estimators=100, random_state=42):\n",
    "#     for col in cols_to_impute:\n",
    "#         if df[col].isna().sum() > 0:  # Cek apakah ada nilai NaN pada kolom\n",
    "#             non_missing_data = df[df[col].notna()]  # Data tanpa nilai NaN untuk training\n",
    "#             X_train = non_missing_data.drop(columns=[col] + drop_cols)  # Fitur training tanpa kolom target\n",
    "#             y_train = non_missing_data[col]  # Target untuk training\n",
    "            \n",
    "#             # Inisiasi Random Forest Regressor dan training\n",
    "#             rf_imputer = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)\n",
    "#             rf_imputer.fit(X_train, y_train)\n",
    "            \n",
    "#             # Melakukan prediksi untuk mengisi nilai NaN\n",
    "#             X_pred = df[df[col].isna()].drop(columns=[col] + drop_cols)\n",
    "#             df.loc[df[col].isna(), col] = rf_imputer.predict(X_pred)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "# cols_to_impute_rf = ['AAI', 'CloudFraction','LST', 'NO2_trop', 'NO2_strat', 'NO2_total', 'TropopausePressure']\n",
    "# df = impute_missing_values(df, cols_to_impute_rf)\n",
    "# test = impute_missing_values(test, cols_to_impute_rf)\n",
    "\n",
    "# # Imputasi untuk kolom dengan missing data sedikit (Mean Imputation)\n",
    "# cols_to_impute_mean = ['GT_NO2']\n",
    "# mean_imputer = SimpleImputer(strategy='mean')\n",
    "# df[cols_to_impute_mean] = mean_imputer.fit_transform(df[cols_to_impute_mean])\n",
    "\n",
    "# # Time series imputation using Iterative Imputer (Multiple Imputation)\n",
    "# time_series_cols = ['Precipitation']\n",
    "# time_series_imputer = IterativeImputer(random_state=42)\n",
    "# df[time_series_cols] = time_series_imputer.fit_transform(df[time_series_cols])\n",
    "# test[time_series_cols] = time_series_imputer.fit_transform(test[time_series_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('train_imputed_with_rf_regressor.csv', index=False)\n",
    "# test.to_csv('test_imputed_with_rf_regressor.csv', index=False)\n",
    "\n",
    "data = pd.read_csv('final_dataset/train_imputed_with_rf_regressor.csv')\n",
    "dtest = pd.read_csv('final_dataset/test_imputed_with_rf_regressor.csv')\n",
    "\n",
    "data.drop(['LAT','LON'],axis=1,inplace=True)\n",
    "dtest.drop(['LAT','LON'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "data['Kmeans'] = kmeans.fit_predict(data[['NO2_strat', 'NO2_total', 'NO2_trop']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data['TropopausePressure'] = scaler.fit_transform(data[['TropopausePressure']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misalnya, data berisi kolom 'Precipitation', 'LST', 'AAI'\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "# Menerapkan transformasi polinomial pada kolom-kolom yang ditentukan\n",
    "poly_features = poly.fit_transform(data[['Precipitation', 'LST', 'AAI']])\n",
    "poly_features_test = poly.fit_transform(dtest[['Precipitation', 'LST', 'AAI']])\n",
    "\n",
    "# Membuat DataFrame baru dengan nama kolom yang sesuai\n",
    "poly_feature_columns = poly.get_feature_names_out(['Precipitation', 'LST', 'AAI'])\n",
    "\n",
    "# Menggabungkan hasilnya dengan data asli (jika perlu)\n",
    "poly_data = pd.DataFrame(poly_features, columns=poly_feature_columns)\n",
    "\n",
    "poly_data.drop(['1','Precipitation','LST','AAI',],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([data, poly_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['GT_NO2'] = pd.to_numeric(result['GT_NO2'], errors='coerce')  # Pastikan target numerik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'GT_NO2'  # Nama kolom target\n",
    "cols = [col for col in result.columns if col != target_col] + [target_col]\n",
    "result = result[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>LST</th>\n",
       "      <th>AAI</th>\n",
       "      <th>CloudFraction</th>\n",
       "      <th>NO2_strat</th>\n",
       "      <th>NO2_total</th>\n",
       "      <th>NO2_trop</th>\n",
       "      <th>TropopausePressure</th>\n",
       "      <th>Kmeans</th>\n",
       "      <th>Precipitation^2</th>\n",
       "      <th>Precipitation LST</th>\n",
       "      <th>Precipitation AAI</th>\n",
       "      <th>LST^2</th>\n",
       "      <th>LST AAI</th>\n",
       "      <th>AAI^2</th>\n",
       "      <th>GT_NO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>277.4618</td>\n",
       "      <td>0.230527</td>\n",
       "      <td>0.559117</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-0.858776</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76985.050459</td>\n",
       "      <td>63.962302</td>\n",
       "      <td>0.053142</td>\n",
       "      <td>31.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.047342</td>\n",
       "      <td>277.9274</td>\n",
       "      <td>-0.074006</td>\n",
       "      <td>0.869309</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>-0.858437</td>\n",
       "      <td>0</td>\n",
       "      <td>9.286295</td>\n",
       "      <td>846.939922</td>\n",
       "      <td>-0.225522</td>\n",
       "      <td>77243.639671</td>\n",
       "      <td>-20.568365</td>\n",
       "      <td>0.005477</td>\n",
       "      <td>42.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>277.1622</td>\n",
       "      <td>0.024470</td>\n",
       "      <td>0.674160</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>-0.859968</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76818.885109</td>\n",
       "      <td>6.782106</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>31.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.200467</td>\n",
       "      <td>277.4052</td>\n",
       "      <td>-0.010442</td>\n",
       "      <td>0.920054</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>-0.858770</td>\n",
       "      <td>0</td>\n",
       "      <td>1.441121</td>\n",
       "      <td>333.015752</td>\n",
       "      <td>-0.012535</td>\n",
       "      <td>76953.644987</td>\n",
       "      <td>-2.896627</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>30.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.274564</td>\n",
       "      <td>278.9034</td>\n",
       "      <td>-0.176178</td>\n",
       "      <td>0.747464</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>-0.859480</td>\n",
       "      <td>0</td>\n",
       "      <td>1.624513</td>\n",
       "      <td>355.480174</td>\n",
       "      <td>-0.224550</td>\n",
       "      <td>77787.106532</td>\n",
       "      <td>-49.136681</td>\n",
       "      <td>0.031039</td>\n",
       "      <td>58.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86579</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>282.6682</td>\n",
       "      <td>-0.434350</td>\n",
       "      <td>0.250490</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>-1.336112</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>79901.311291</td>\n",
       "      <td>-122.776903</td>\n",
       "      <td>0.188660</td>\n",
       "      <td>39.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86580</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>272.3992</td>\n",
       "      <td>-1.479808</td>\n",
       "      <td>0.402424</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.098240</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>74201.324161</td>\n",
       "      <td>-403.098429</td>\n",
       "      <td>2.189831</td>\n",
       "      <td>30.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86581</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>284.9800</td>\n",
       "      <td>-0.157753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>-1.340838</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>81213.600400</td>\n",
       "      <td>-44.956553</td>\n",
       "      <td>0.024886</td>\n",
       "      <td>28.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86582</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>283.1990</td>\n",
       "      <td>-0.798636</td>\n",
       "      <td>0.399524</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>-1.336939</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>80201.673601</td>\n",
       "      <td>-226.173003</td>\n",
       "      <td>0.637820</td>\n",
       "      <td>21.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86583</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>282.6390</td>\n",
       "      <td>-0.434482</td>\n",
       "      <td>0.250530</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>-1.336113</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>79884.804321</td>\n",
       "      <td>-122.801554</td>\n",
       "      <td>0.188775</td>\n",
       "      <td>40.350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86584 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precipitation       LST       AAI  CloudFraction  NO2_strat  NO2_total  \\\n",
       "0           0.000000  277.4618  0.230527       0.559117   0.000024   0.000117   \n",
       "1           3.047342  277.9274 -0.074006       0.869309   0.000024   0.000127   \n",
       "2           0.000000  277.1622  0.024470       0.674160   0.000024   0.000086   \n",
       "3           1.200467  277.4052 -0.010442       0.920054   0.000024   0.000124   \n",
       "4           1.274564  278.9034 -0.176178       0.747464   0.000024   0.000116   \n",
       "...              ...       ...       ...            ...        ...        ...   \n",
       "86579       0.000000  282.6682 -0.434350       0.250490   0.000032   0.000643   \n",
       "86580       0.000000  272.3992 -1.479808       0.402424   0.000025   0.000101   \n",
       "86581       0.000000  284.9800 -0.157753       0.000000   0.000031   0.000153   \n",
       "86582       0.000000  283.1990 -0.798636       0.399524   0.000031   0.000717   \n",
       "86583       0.000000  282.6390 -0.434482       0.250530   0.000032   0.000643   \n",
       "\n",
       "       NO2_trop  TropopausePressure  Kmeans  Precipitation^2  \\\n",
       "0      0.000163           -0.858776       0         0.000000   \n",
       "1      0.000123           -0.858437       0         9.286295   \n",
       "2      0.000089           -0.859968       0         0.000000   \n",
       "3      0.000123           -0.858770       0         1.441121   \n",
       "4      0.000164           -0.859480       0         1.624513   \n",
       "...         ...                 ...     ...              ...   \n",
       "86579  0.000579           -1.336112       2         0.000000   \n",
       "86580  0.000077            0.098240       0         0.000000   \n",
       "86581  0.000122           -1.340838       0         0.000000   \n",
       "86582  0.000606           -1.336939       2         0.000000   \n",
       "86583  0.000579           -1.336113       2         0.000000   \n",
       "\n",
       "       Precipitation LST  Precipitation AAI         LST^2     LST AAI  \\\n",
       "0               0.000000           0.000000  76985.050459   63.962302   \n",
       "1             846.939922          -0.225522  77243.639671  -20.568365   \n",
       "2               0.000000           0.000000  76818.885109    6.782106   \n",
       "3             333.015752          -0.012535  76953.644987   -2.896627   \n",
       "4             355.480174          -0.224550  77787.106532  -49.136681   \n",
       "...                  ...                ...           ...         ...   \n",
       "86579           0.000000          -0.000000  79901.311291 -122.776903   \n",
       "86580           0.000000          -0.000000  74201.324161 -403.098429   \n",
       "86581           0.000000          -0.000000  81213.600400  -44.956553   \n",
       "86582           0.000000          -0.000000  80201.673601 -226.173003   \n",
       "86583           0.000000          -0.000000  79884.804321 -122.801554   \n",
       "\n",
       "          AAI^2  GT_NO2  \n",
       "0      0.053142  31.000  \n",
       "1      0.005477  42.000  \n",
       "2      0.000599  31.000  \n",
       "3      0.000109  30.000  \n",
       "4      0.031039  58.000  \n",
       "...         ...     ...  \n",
       "86579  0.188660  39.750  \n",
       "86580  2.189831  30.125  \n",
       "86581  0.024886  28.325  \n",
       "86582  0.637820  21.250  \n",
       "86583  0.188775  40.350  \n",
       "\n",
       "[86584 rows x 16 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length, output_length=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length - output_length + 1):\n",
    "        X.append(data[i:i+seq_length])  # Ambil input sequence\n",
    "        y.append(data[i+seq_length:i+seq_length+output_length])  # Output beberapa langkah ke depan\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 10.05865473721987\n"
     ]
    }
   ],
   "source": [
    "seq_length = 15\n",
    "output_length = 1  # Prediksi 1 langkah ke depan\n",
    "X, y = create_sequences(result['GT_NO2'].values, seq_length, output_length)\n",
    "\n",
    "# Split result menjadi training dan testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Model SGBRegressor\n",
    "model = HistGradientBoostingRegressor(loss=\"squared_error\", max_iter=100)\n",
    "model.fit(X_train, y_train.ravel())  # `.ravel()` agar sesuai dengan input\n",
    "\n",
    "# Prediksi\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "from sklearn.metrics import root_mean_squared_error \n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Simpan model machine learning\n",
    "joblib.dump(model, 'model.pkl')\n",
    "\n",
    "# Simpan scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Simpan KMeans\n",
    "joblib.dump(kmeans, 'kmeans.pkl')\n",
    "\n",
    "# Simpan PolynomialFeatures\n",
    "joblib.dump(poly, 'poly.pkl')\n",
    "\n",
    "print(\"Model dan preprocessing berhasil disimpan!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.   , 42.   , 31.   , ..., 58.   , 26.   , 38.   ],\n",
       "       [42.   , 31.   , 30.   , ..., 26.   , 38.   , 34.   ],\n",
       "       [31.   , 30.   , 58.   , ..., 38.   , 34.   , 41.   ],\n",
       "       ...,\n",
       "       [29.225, 27.675, 19.875, ..., 56.275, 39.75 , 30.125],\n",
       "       [27.675, 19.875, 24.225, ..., 39.75 , 30.125, 28.325],\n",
       "       [19.875, 24.225, 56.275, ..., 30.125, 28.325, 21.25 ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5968895,
     "sourceId": 9749552,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
